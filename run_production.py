#!/usr/bin/env python3
"""
üöÄ PRODUCTION RUNNER - DLSD Evidence Collector
–û–±—Ä–æ–±–∫–∞ –≤—Å—ñ—Ö —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç—ñ–≤ –∑ Google Sheets –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º:
- –°–∏–Ω–æ–Ω—ñ–º—ñ–≤ –∑—ñ —Å—Ç–æ–≤–ø—á–∏–∫–∞ E
- Existing links –∑—ñ —Å—Ç–æ–≤–ø—á–∏–∫–∞ G (–ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç)
- NCBI fallback –∑ —Ä–µ–∞–ª—å–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏
- –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ Google Sheets
"""
import sys
import os
import json
import time
from datetime import datetime
from typing import Dict, List, Any

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –∫–æ–¥—É–≤–∞–Ω–Ω—è –¥–ª—è Windows
if sys.platform == "win32":
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer)
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer)

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from modules.sheets_reader import sheets_reader
from processes.pipeline import pipeline
from modules.sheets_writer import sheets_writer

class ProductionRunner:
    """Production runner –¥–ª—è –æ–±—Ä–æ–±–∫–∏ –≤—Å—ñ—Ö —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç—ñ–≤"""

    def __init__(self):
        self.start_time = datetime.now()
        self.processed_count = 0
        self.success_count = 0
        self.error_count = 0
        self.results_log = []

    def run_production(self, limit: int = None, start_from: int = 1, ai_model: str = None):
        """
        –ó–∞–ø—É—Å–∫ –ø—Ä–æ–¥–∞–∫—à–∏–Ω –æ–±—Ä–æ–±–∫–∏

        Args:
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç—ñ–≤ (None = –≤—Å—ñ)
            start_from: –ü–æ—á–∞—Ç–∏ –∑ —è–∫–æ–≥–æ —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç–∞
            ai_model: –ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞ AI –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è (claude/openai/gemini)
        """
        print("DLSD EVIDENCE COLLECTOR - PRODUCTION MODE")
        print("=" * 60)
        print(f"Start time: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}")

        if limit:
            print(f"Processing: {limit} ingredients (starting from #{start_from})")
        else:
            print(f"Processing: ALL 6,457 ingredients (starting from #{start_from})")

        if ai_model:
            print(f"AI Model: {ai_model.upper()} ONLY")
        else:
            print(f"AI Model: Multi-AI (claude -> openai -> gemini)")

        print("=" * 60)

        # 1. –ß–∏—Ç–∞—î–º–æ —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç–∏ –∑ Google Sheets
        print("\nReading ingredients from Google Sheets...")
        ingredients_data = sheets_reader.read_ingredients(limit=limit)

        if not ingredients_data:
            print("ERROR: No ingredients found")
            return

        # –§—ñ–ª—å—Ç—Ä—É—î–º–æ —è–∫—â–æ start_from > 1
        if start_from > 1:
            ingredients_data = ingredients_data[start_from-1:]
            print(f"Starting from ingredient #{start_from}")

        print(f"Found {len(ingredients_data)} ingredients")

        # 2. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ Google Sheets –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        print("\nInitializing Google Sheets for results...")
        if not pipeline.initialize_sheets():
            print("ERROR: Failed to initialize Google Sheets")
            return

        print(f"Google Sheets ready: {sheets_writer.get_sheet_url()}")

        # 3. –û–±—Ä–æ–±–ª—è—î–º–æ –∫–æ–∂–µ–Ω —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç
        print(f"\nProcessing ingredients...")
        print("-" * 60)

        for i, ing_data in enumerate(ingredients_data, start_from):
            ingredient = ing_data.get("ingredient", "")
            synonyms = ing_data.get("synonyms", [])
            existing_links = ing_data.get("existing_links", [])

            try:
                self._process_single_ingredient(i, ingredient, synonyms, existing_links, len(ingredients_data) + start_from - 1, ai_model)

                # Progress save –∫–æ–∂–Ω—ñ 10 —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç—ñ–≤
                if self.processed_count % 10 == 0:
                    self._save_progress()

                # –ù–µ–≤–µ–ª–∏–∫–∞ –ø–∞—É–∑–∞ –º—ñ–∂ —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç–∞–º–∏
                time.sleep(1)

            except KeyboardInterrupt:
                print(f"\nINTERRUPTED by user")
                break
            except Exception as e:
                print(f"\nCRITICAL ERROR processing {ingredient}: {e}")
                self.error_count += 1

        # 4. –§—ñ–Ω–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç
        self._print_final_report()
        self._save_final_results()

    def _process_single_ingredient(self, index: int, ingredient: str, synonyms: List[str], existing_links: List[str], total: int, ai_model: str = None):
        """–û–±—Ä–æ–±–∫–∞ –æ–¥–Ω–æ–≥–æ —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç–∞"""

        print(f"\n[{index}/{total}] Processing: {ingredient}")

        if synonyms:
            print(f"   Synonyms: {', '.join(synonyms[:3])}{'...' if len(synonyms) > 3 else ''}")

        if existing_links:
            print(f"   Existing links: {len(existing_links)} links from column G")

        # –ó–∞–ø—É—Å–∫–∞—î–º–æ pipeline
        start_time = time.time()

        try:
            # –ü–µ—Ä–µ–¥–∞—î–º–æ ai_model –¥–æ pipeline —è–∫—â–æ –≤–∫–∞–∑–∞–Ω–æ
            if ai_model:
                result = pipeline.process_ingredient(ingredient, synonyms, existing_links=existing_links, ai_model=ai_model)
            else:
                result = pipeline.process_ingredient(ingredient, synonyms, existing_links=existing_links)

            # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∑ –Ω–æ–≤–æ—é A-G —Å—Ç—Ä—É–∫—Ç—É—Ä–æ—é
            # C: –ê–∫—Ç–∏–≤–Ω—ñ —Å–ø–æ–ª—É–∫–∏ —Ç–µ–ø–µ—Ä —î —Å—Ç—Ä–æ–∫–æ—é, –Ω–µ —Å–ø–∏—Å–∫–æ–º
            compounds_text = result.get('C_aktyvni_spoluky', '')
            compounds_count = len(compounds_text.split(',')) if compounds_text else 0

            # D: –î–æ–∑—É–≤–∞–Ω–Ω—è
            has_dose = bool(result.get('D_dozuvannya', ''))

            # F: –¶–∏—Ç–∞—Ç–∏ —Ç–µ–ø–µ—Ä —î —Å—Ç—Ä–æ–∫–æ—é, –Ω–µ —Å–ø–∏—Å–∫–æ–º
            citations_text = result.get('F_tsytaty', '')
            citations_count = len(citations_text.split(';')) if citations_text else 0

            processing_time = round(time.time() - start_time, 1)

            if compounds_count > 0 or has_dose:
                status = "SUCCESS"
                self.success_count += 1
            else:
                status = "NO DATA"

            print(f"   {status}: {compounds_count} compounds, dose: {'Yes' if has_dose else 'No'}, {citations_count} citations ({processing_time}s)")

            # –õ–æ–≥—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            self.results_log.append({
                "index": index,
                "ingredient": ingredient,
                "compounds": compounds_count,
                "has_dose": has_dose,
                "citations": citations_count,
                "processing_time": processing_time,
                "status": "success" if (compounds_count > 0 or has_dose) else "no_data",
                "synonyms_used": len(synonyms),
                "existing_links_used": len(existing_links)
            })

        except Exception as e:
            print(f"   ERROR: {str(e)[:100]}")
            self.error_count += 1

            self.results_log.append({
                "index": index,
                "ingredient": ingredient,
                "error": str(e),
                "status": "error"
            })

        self.processed_count += 1

    def _save_progress(self):
        """–ó–±–µ—Ä—ñ–≥–∞—î –ø—Ä–æ–º—ñ–∂–Ω–∏–π –ø—Ä–æ–≥—Ä–µ—Å"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        progress_file = f"output/production_progress_{timestamp}.json"

        os.makedirs("output", exist_ok=True)

        progress_data = {
            "timestamp": timestamp,
            "processed_count": self.processed_count,
            "success_count": self.success_count,
            "error_count": self.error_count,
            "runtime": str(datetime.now() - self.start_time),
            "results": self.results_log[-10:]  # –û—Å—Ç–∞–Ω–Ω—ñ 10 —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        }

        with open(progress_file, 'w', encoding='utf-8') as f:
            json.dump(progress_data, f, indent=2, ensure_ascii=False)

    def _print_final_report(self):
        """–í–∏–≤–æ–¥–∏—Ç—å —Ñ—ñ–Ω–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç"""
        end_time = datetime.now()
        total_time = end_time - self.start_time

        print(f"\nPRODUCTION COMPLETED")
        print("=" * 60)
        print(f"Total processed: {self.processed_count}")
        print(f"Success: {self.success_count} ({round(self.success_count/max(1,self.processed_count)*100, 1)}%)")
        print(f"No data: {self.processed_count - self.success_count - self.error_count}")
        print(f"Errors: {self.error_count} ({round(self.error_count/max(1,self.processed_count)*100, 1)}%)")
        print(f"Total time: {total_time}")
        print(f"Google Sheets: {sheets_writer.get_sheet_url()}")
        print("=" * 60)

        # –¢–æ–ø —É—Å–ø—ñ—à–Ω–∏—Ö —ñ–Ω–≥—Ä–µ–¥—ñ—î–Ω—Ç—ñ–≤
        successful = [r for r in self.results_log if r.get("status") == "success"]
        if successful:
            print(f"\nTOP SUCCESSFUL INGREDIENTS:")
            for r in sorted(successful, key=lambda x: x.get("compounds", 0) + (1 if x.get("has_dose") else 0), reverse=True)[:5]:
                print(f"   {r['index']}. {r['ingredient']} - {r['compounds']} compounds, dose: {'Yes' if r['has_dose'] else 'No'}")

    def _save_final_results(self):
        """–ó–±–µ—Ä—ñ–≥–∞—î —Ñ—ñ–Ω–∞–ª—å–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        final_file = f"output/PRODUCTION_RESULTS_{timestamp}.json"

        os.makedirs("output", exist_ok=True)

        final_data = {
            "production_run": {
                "start_time": self.start_time.isoformat(),
                "end_time": datetime.now().isoformat(),
                "total_processed": self.processed_count,
                "success_count": self.success_count,
                "error_count": self.error_count,
                "success_rate": round(self.success_count/max(1,self.processed_count)*100, 2)
            },
            "system_config": {
                "uses_synonyms": True,
                "uses_existing_links": True,
                "ncbi_fallback": True,
                "ai_models": ["claude", "openai", "gemini"],
                "saves_to_sheets": True
            },
            "detailed_results": self.results_log,
            "sheets_url": sheets_writer.get_sheet_url()
        }

        with open(final_file, 'w', encoding='utf-8') as f:
            json.dump(final_data, f, indent=2, ensure_ascii=False)

        print(f"\nResults saved: {final_file}")

def main():
    """Main entry point"""
    import argparse

    parser = argparse.ArgumentParser(description='DLSD Evidence Collector - Production Run')
    parser.add_argument('--limit', type=int, help='Maximum number of ingredients to process')
    parser.add_argument('--start-from', type=int, default=1, help='Start from ingredient number')
    parser.add_argument('--test', action='store_true', help='Run test with first 10 ingredients')
    parser.add_argument('--ai-model', choices=['claude', 'openai', 'gemini'], help='Use specific AI model only')

    args = parser.parse_args()

    if args.test:
        args.limit = 10
        print("TEST MODE: Processing first 10 ingredients")

    runner = ProductionRunner()
    runner.run_production(limit=args.limit, start_from=args.start_from, ai_model=args.ai_model)

if __name__ == "__main__":
    main()